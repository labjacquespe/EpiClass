# Justfile for managing test suite with multiple Python versions.
# Uses `uv` (https://pypi.org/project/uv/) for environment and dependency management.
# Uses `pytest` for running tests.

# List all available recipes
list:
    @just --list
    @echo "Use 'just <recipe>' to run a specific recipe."

# Generate timestamp for log files
_timestamp := `date +"%Y%m%d_%H%M%S"`

# Environment check - only runs when explicitly called
check-env:
    @echo "üîç Checking environment..."
    @which uv > /dev/null || (echo "‚ùå uv not found" && exit 1)
    @echo "‚úÖ Environment OK"

# Compile requirements for a specific Python version (separate step for reproducibility)
compile python_version:
    #!/usr/bin/env bash
    set -euo pipefail
    v="{{python_version}}"
    timestamp="{{_timestamp}}"
    log="logs/${timestamp}_py${v}_1-compile.log"
    echo "üìã Compiling requirements for Python ${v}..."

    # Ensure requirements are compatible with the specified Python version
    # Will fail if not compatible
    uv pip compile -p=${v} ../requirements/req_core.in &>> $log

    echo "‚úÖ Requirements compiled for Python ${v}"
    echo "üìÑ Generated: ../requirements/req_core_${v}.txt"

# Run tests for a specific Python version using pre-compiled requirements
# Optional: pass test_filter to select specific tests (e.g., just test 3.11 "test_foo")
test python_version test_filter="":
    #!/usr/bin/env bash
    set -euo pipefail

    mkdir -p logs
    mkdir -p envs

    # parameters
    v="{{python_version}}"
    test_filter="{{test_filter}}"

    # files
    venv_path="./envs/venv_test_${v}"
    req_file="../requirements/req_test_${v}.txt"

    timestamp="{{_timestamp}}"
    log_install="logs/${timestamp}_py${v}_2-install.log"
    log_pytest="logs/${timestamp}_py${v}_3-pytest.log"

    echo "üöÄ Starting test sequence for Python ${v}..."
    echo "üìù Logs will be saved with timestamp: ${timestamp}"

    # Ensure requirements are compatible with the specified Python version
    just compile ${v}

    # Create fresh virtual environment (--clear removes existing one)
    echo "üîÑ Creating fresh virtual environment for Python ${v}..."
    uv venv --seed --clear -p=${v} "$venv_path"
    . "$venv_path/bin/activate"

    echo "üì¶ Installing package with test dependencies..."
    python ../install.py test --freeze $req_file &>> $log_install

    echo "üß™ Running pytest for Python ${v}..."
    if [ -n "$test_filter" ]; then
        echo "üîç Filtering tests with: -k '$test_filter'"
        pytest --tb=short -k "$test_filter" ../tests/ &>> $log_pytest || true
    else
        pytest --tb=short ../tests/ &>> $log_pytest || true
    fi

    # Optionally filter out known benign warnings "i" for in-place edit
    del_str="[LightGBM] [Warning] No further splits with positive gain, best gain: -inf"
    sed -i "/$del_str/d" "$log_pytest" || true

    echo "‚úÖ Tests for Python ${v} completed"
    grep -E '[0-9]+ (passed|failed|skipped)' $log_pytest || true
    echo "check logs/ directory for detailled results."

# Compile requirements for all Python versions
compile-all: check-env
    just compile 3.10
    just compile 3.11
    just compile 3.12
    @echo "‚úÖ All requirements compiled"

# Run all tests in parallel for all Python versions
test-all test_filter="": check-env
    #!/usr/bin/env bash
    set -euo pipefail

    timestamp="{{_timestamp}}"
    echo "üïí Global run timestamp: ${timestamp}"
    mkdir -p logs

    versions=(3.10 3.11 3.12)
    pids=()

    for v in "${versions[@]}"; do
        echo "‚ñ∂ Starting tests for Python ${v} (no console output, check logs)..."
        # Silence test output entirely except for the overview log
        just test "$v" "{{test_filter}}" \
            &> "logs/${timestamp}_py${v}_0-overview.log" &
        pids+=($!)
    done

    echo "üèÉ Running tests in parallel..."
    exit_code=0
    for pid in "${pids[@]}"; do
        if ! wait "$pid"; then
            exit_code=1
        fi
    done

    echo
    echo "üìä Final summary"
    echo "----------------------------------------"
    for v in "${versions[@]}"; do
        # find pytest log produced inside `just test`
        log_file=$(ls logs/${timestamp}*${v}*pytest.log 2>/dev/null | sort | tail -n 1 || true)
        if [ -n "$log_file" ]; then
            summary=$(grep -E '[0-9]+ (passed|failed|skipped)' "$log_file" | tail -n 1 || true)
            if [ -n "$summary" ]; then
                printf "Python %-5s ‚Üí %s\n" "$v" "$summary"
            else
                printf "Python %-5s ‚Üí (no summary found, see %s)\n" "$v" "$log_file"
            fi
        else
            printf "Python %-5s ‚Üí (no pytest log found)\n" "$v"
        fi
    done
    echo "----------------------------------------"
    echo

    if [ $exit_code -eq 0 ]; then
        echo "‚úÖ All test runs succeeded."
    else
        echo "‚ùå One or more test runs failed. Check logs/ for details."
    fi

    exit $exit_code

# Clean up generated files (WARNING: deletes all logs!)
clean:
    #!/usr/bin/env bash
    echo "‚ö†Ô∏è  This will delete ALL log files and cache directories!"
    echo "Press Ctrl+C to cancel, or Enter to continue..."
    read -r
    echo "üßπ Cleaning up..."
    for dir in logs envs ./venv __pycache__ .pytest_cache; do
        if [ -d "$dir" ]; then
            echo "Removing $dir..."
            rm -rf "$dir"
        fi
    done
    echo "‚úÖ Cleanup complete"
